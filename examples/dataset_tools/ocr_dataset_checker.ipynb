{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib64/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "from _paths import nomeroff_net_dir\n",
    "\n",
    "from nomeroff_net.pipes.number_plate_text_readers.base.ocr import OCR\n",
    "from nomeroff_net.tools.mcm import modelhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto download latest dataset\n",
    "from nomeroff_net.tools import modelhub\n",
    "\n",
    "# auto download latest dataset\n",
    "#info = modelhub.download_dataset_for_model(\"EuUa1995\")\n",
    "#PATH_TO_DATASET = info[\"dataset_path\"]\n",
    "PATH_TO_DATASET = os.path.join(nomeroff_net_dir, \"data/dataset/TextDetector/ocr_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(model_path='latest',\n",
    "           text_detector_name = \"eu_ua_2004_2015\",\n",
    "           img_format = \"png\",\n",
    "           root_dir=os.path.join(PATH_TO_DATASET, \"test\"),\n",
    "           predicted_part_size=1,\n",
    "           acc_less_than = 0.7,\n",
    "           replace_tamplate = None,\n",
    "           model_conf = None):\n",
    "    if replace_tamplate is None:\n",
    "        replace_tamplate = {'moderation': {'isModerated': 1, 'moderatedBy': 'ApelSYN'}}\n",
    "    if model_conf is None:\n",
    "        model_conf = copy.deepcopy(modelhub.models[text_detector_name])\n",
    "    text_detector = OCR(model_name=text_detector_name, **model_conf)\n",
    "    text_detector.init_label_converter()\n",
    "    text_detector.load(model_path)\n",
    "\n",
    "    ann_dir = os.path.join(root_dir, \"ann\")\n",
    "    jsons = []\n",
    "    jsons_paths = []\n",
    "    for dir_name, subdir_list, file_list in os.walk(ann_dir):\n",
    "        for fname in file_list:\n",
    "            fname = os.path.join(ann_dir, fname)\n",
    "            jsons_paths.append(fname)\n",
    "            with open(fname) as jsonF:\n",
    "                jsonData = json.load(jsonF)\n",
    "            jsons.append(jsonData)\n",
    "    print(\"LOADED {} ANNOTATIONS\".format(len(jsons)))\n",
    "\n",
    "    img_dir = os.path.join(root_dir, \"img\")\n",
    "    imgs = []\n",
    "    for j in jsons:\n",
    "        img_path =os.path.join(img_dir, \"{}.{}\".format(j[\"name\"], img_format))\n",
    "        img = cv2.imread(img_path)\n",
    "        imgs.append(img)\n",
    "    print(\"LOADED {} IMAGES\".format(len(imgs)))\n",
    "\n",
    "    predicted = []\n",
    "    accs      = []\n",
    "    N = math.ceil(len(imgs) / predicted_part_size)\n",
    "    for i in range(N):\n",
    "        part = i*predicted_part_size\n",
    "        part_imgs = imgs[part:part+predicted_part_size]\n",
    "        xs = text_detector.preprocess(part_imgs)\n",
    "        predicted_part, net_out_value_part = text_detector.predict(xs, return_acc=True)\n",
    "        predicted += predicted_part\n",
    "\n",
    "\n",
    "        # get accuracy\n",
    "        if acc_less_than >= 1:\n",
    "            # not process acc\n",
    "            accs  += [1 for _predicted in predicted_part]\n",
    "            continue\n",
    "        # process accuracy\n",
    "        acc_part = []\n",
    "        for _predicted, _net_out_value in zip(predicted_part, net_out_value_part):\n",
    "            acc = text_detector.get_acc([_net_out_value], [_predicted])\n",
    "            acc_part.append(acc)\n",
    "        accs  += acc_part\n",
    "\n",
    "\n",
    "    print(\"PREDICTED {} IMAGES\".format(len(predicted)))\n",
    "\n",
    "    err_cnt = 0\n",
    "    for i in range(len(jsons_paths)):\n",
    "        json_path      = jsons_paths[i]\n",
    "        predicted_item = predicted[i]\n",
    "        jsonData       = jsons[i]\n",
    "        acc            = accs[i]\n",
    "        jsonData[\"moderation\"][\"predicted\"] = predicted_item\n",
    "\n",
    "        if jsonData[\"description\"].lower() == jsonData[\"moderation\"][\"predicted\"].lower() and acc > acc_less_than:\n",
    "            jsonData[\"moderation\"][\"isModerated\"] = 1\n",
    "        else:\n",
    "            print(\"Predicted '{}' with acc {}, real: '{}' in file {}\".format(\n",
    "                jsonData[\"moderation\"][\"predicted\"].lower(),\n",
    "                acc,\n",
    "                jsonData[\"description\"].lower(),\n",
    "                json_path))\n",
    "            err_cnt = err_cnt+1\n",
    "            jsonData[\"moderation\"][\"isModerated\"] = 0\n",
    "        with open(json_path, \"w\", encoding='utf8') as jsonWF:\n",
    "            json.dump(jsonData, jsonWF,  ensure_ascii=False)\n",
    "\n",
    "    print(\"Error detection count: {}\".format(err_cnt))\n",
    "    print(\"Accuracy: {}\".format(1-err_cnt/len(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib64/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED 4 ANNOTATIONS\n",
      "LOADED 4 IMAGES\n",
      "PREDICTED 4 IMAGES\n",
      "Predicted 'ap222bi' with acc 0.8141323924064636, real: '0038sc' in file /var/www/nomeroff-net33/examples/ju/dataset_tools/../../../data/dataset/TextDetector/ocr_example/test/ann/0038SC-0.json\n",
      "Predicted 'bo2514kct' with acc 0.9932663440704346, real: '2914 kc-7' in file /var/www/nomeroff-net33/examples/ju/dataset_tools/../../../data/dataset/TextDetector/ocr_example/test/ann/10001_2914KC7_0.json\n",
      "Predicted 'b371h2o' with acc 0.9075599908828735, real: 'x371hk96' in file /var/www/nomeroff-net33/examples/ju/dataset_tools/../../../data/dataset/TextDetector/ocr_example/test/ann/1000_X371HK96_0.json\n",
      "Error detection count: 3\n",
      "Accuracy: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/www/nomeroff-net33/examples/ju/dataset_tools/../../../nomeroff_net/pipes/number_plate_text_readers/base/ocr.py:247: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  pred_texts = decode_batch(torch.Tensor(net_out_value), self.label_converter)\n"
     ]
    }
   ],
   "source": [
    "compare(model_path=\"latest\", acc_less_than = 0.75, model_conf = {\n",
    "      \"letters\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\",\n",
    "              \"I\", \"K\", \"M\", \"O\", \"P\", \"T\", \"X\", \"Y\", \"Z\"],\n",
    "      \"max_text_len\": 9\n",
    "     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # or load your own trained model\n",
    "# compare(\n",
    "#     model_path=\"../../../data/models/shufflenet_v2_x2_0/anpr_ocr_eu_2004_2015_2022_11_11_shufflenet_v2_x2_0.ckpt\",\n",
    "#     acc_less_than = 0.75,\n",
    "#     model_conf={\n",
    "#       \"backbone\": \"shufflenet_v2_x2_0\",\n",
    "#       \"letters\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\",\n",
    "#                   \"I\", \"K\", \"M\", \"O\", \"P\", \"T\", \"X\", \"Y\", \"Z\"],\n",
    "#       \"max_text_len\": 8,\n",
    "#       \"height\": 50,\n",
    "#       \"width\": 200,\n",
    "#       \"color_channels\": 3,\n",
    "#       \"bidirectional\": True,\n",
    "#       \"hidden_size\": 32,\n",
    "#       \"linear_size\": 416\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ",
   "language": "python",
   "name": "py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
